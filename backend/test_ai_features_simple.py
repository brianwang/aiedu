#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½è¯„åˆ†ä¸é”™é¢˜è®²è§£åŠŸèƒ½ç®€åŒ–æµ‹è¯•è„šæœ¬
ç›´æ¥æµ‹è¯•AIæœåŠ¡æ ¸å¿ƒåŠŸèƒ½ï¼Œä¸ä¾èµ–æ•°æ®åº“
"""

import asyncio
import json
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# æ¨¡æ‹Ÿæ•°æ®åº“ä¼šè¯
class MockSession:
    def __init__(self):
        pass
    
    def query(self, model):
        return MockQuery()
    
    def filter(self, condition):
        return self
    
    def all(self):
        return []

class MockQuery:
    def __init__(self):
        pass
    
    def filter(self, condition):
        return self
    
    def join(self, model):
        return self
    
    def all(self):
        return []

# ç›´æ¥å¯¼å…¥AIæœåŠ¡ç±»ï¼Œé¿å…æ•°æ®åº“ä¾èµ–
import importlib.util
spec = importlib.util.spec_from_file_location("ai_service", "app/services/ai_service.py")
ai_service_module = importlib.util.module_from_spec(spec)

# æ¨¡æ‹Ÿå¿…è¦çš„å¯¼å…¥
class MockQuestion:
    pass

class MockQuestionCategory:
    pass

class MockUser:
    pass

class MockStudySession:
    pass

class MockWrongQuestion:
    pass

# è®¾ç½®æ¨¡æ‹Ÿå¯¹è±¡
ai_service_module.Question = MockQuestion
ai_service_module.QuestionCategory = MockQuestionCategory
ai_service_module.User = MockUser
ai_service_module.StudySession = MockStudySession
ai_service_module.WrongQuestion = MockWrongQuestion

# æ‰§è¡Œæ¨¡å—
spec.loader.exec_module(ai_service_module)

class SimpleAIFeaturesTest:
    def __init__(self):
        # åˆ›å»ºAIæœåŠ¡å®ä¾‹
        self.ai_service = ai_service_module.AIService()
        self.test_results = []
        
    async def test_smart_grading(self):
        """æµ‹è¯•æ™ºèƒ½è¯„åˆ†åŠŸèƒ½"""
        print("ğŸ” æµ‹è¯•æ™ºèƒ½è¯„åˆ†åŠŸèƒ½...")
        
        test_cases = [
            {
                "name": "æ•°å­¦é€‰æ‹©é¢˜ - å®Œå…¨æ­£ç¡®",
                "question": "è®¡ç®— 2 + 3 Ã— 4 çš„ç»“æœ",
                "standard_answer": "14",
                "student_answer": "14",
                "question_type": "single_choice",
                "max_score": 5
            },
            {
                "name": "æ•°å­¦å¡«ç©ºé¢˜ - éƒ¨åˆ†æ­£ç¡®",
                "question": "è§£æ–¹ç¨‹ï¼šx + 5 = 12",
                "standard_answer": "x = 7",
                "student_answer": "7",
                "question_type": "fill_blank",
                "max_score": 5
            },
            {
                "name": "è¯­æ–‡ä¸»è§‚é¢˜ - è¡¨è¾¾ä¸è§„èŒƒ",
                "question": "è¯·ç®€è¿°ã€Šçº¢æ¥¼æ¢¦ã€‹çš„ä¸»é¢˜æ€æƒ³",
                "standard_answer": "ã€Šçº¢æ¥¼æ¢¦ã€‹é€šè¿‡è´¾å®ç‰ã€æ—é»›ç‰ç­‰äººçš„çˆ±æƒ…æ‚²å‰§ï¼Œæ·±åˆ»æ­ç¤ºäº†å°å»ºç¤¾ä¼šçš„è…æœ½å’Œæ²¡è½ï¼Œè¡¨è¾¾äº†ä½œè€…å¯¹è‡ªç”±ã€å¹³ç­‰ã€çœŸæƒ…çš„å‘å¾€ã€‚",
                "student_answer": "çº¢æ¥¼æ¢¦è®²çš„æ˜¯è´¾å®ç‰å’Œæ—é»›ç‰çš„çˆ±æƒ…æ•…äº‹ï¼Œåæ˜ äº†å°å»ºç¤¾ä¼šçš„é»‘æš—",
                "question_type": "essay",
                "max_score": 10
            },
            {
                "name": "è‹±è¯­ç¿»è¯‘é¢˜ - ç­”æ¡ˆé”™è¯¯",
                "question": "ç¿»è¯‘ï¼šI love studying mathematics.",
                "standard_answer": "æˆ‘å–œæ¬¢å­¦ä¹ æ•°å­¦ã€‚",
                "student_answer": "æˆ‘çˆ±å­¦ä¹ è‹±è¯­ã€‚",
                "question_type": "short_answer",
                "max_score": 5
            },
            {
                "name": "ç‰©ç†è®¡ç®—é¢˜ - æœªä½œç­”",
                "question": "è®¡ç®—ç‰©ä½“åœ¨é‡åŠ›ä½œç”¨ä¸‹çš„åŠ é€Ÿåº¦ï¼ˆg = 9.8 m/sÂ²ï¼‰",
                "standard_answer": "9.8 m/sÂ²",
                "student_answer": "",
                "question_type": "short_answer",
                "max_score": 5
            }
        ]
        
        for i, case in enumerate(test_cases, 1):
            print(f"\nğŸ“ æµ‹è¯•æ¡ˆä¾‹ {i}: {case['name']}")
            
            try:
                result = await self.ai_service.smart_grading(
                    case["question"],
                    case["standard_answer"],
                    case["student_answer"],
                    case["question_type"],
                    case["max_score"]
                )
                
                # éªŒè¯ç»“æœæ ¼å¼
                required_fields = [
                    "score", "accuracy_score", "logic_score", 
                    "expression_score", "creativity_score", "overall_accuracy",
                    "detailed_feedback", "learning_insights", "encouragement"
                ]
                
                missing_fields = [field for field in required_fields if field not in result]
                if missing_fields:
                    print(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                    self.test_results.append({
                        "test": f"æ™ºèƒ½è¯„åˆ† - {case['name']}",
                        "status": "å¤±è´¥",
                        "error": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}"
                    })
                else:
                    print(f"âœ… è¯„åˆ†ç»“æœ:")
                    print(f"   æ€»åˆ†: {result['score']}/{case['max_score']}")
                    print(f"   å†…å®¹å‡†ç¡®æ€§: {result['accuracy_score']}")
                    print(f"   é€»è¾‘å®Œæ•´æ€§: {result['logic_score']}")
                    print(f"   è¡¨è¾¾è§„èŒƒæ€§: {result['expression_score']}")
                    print(f"   åˆ›æ–°æ€ç»´: {result['creativity_score']}")
                    print(f"   æ€»ä½“å‡†ç¡®åº¦: {result['overall_accuracy']}%")
                    print(f"   é¼“åŠ±è¯è¯­: {result['encouragement']}")
                    
                    # æ˜¾ç¤ºè¯¦ç»†åé¦ˆ
                    feedback = result['detailed_feedback']
                    print(f"   ä¼˜ç‚¹: {', '.join(feedback['strengths'])}")
                    print(f"   ä¸è¶³: {', '.join(feedback['weaknesses'])}")
                    print(f"   æ”¹è¿›å»ºè®®: {', '.join(feedback['improvement_suggestions'])}")
                    
                    self.test_results.append({
                        "test": f"æ™ºèƒ½è¯„åˆ† - {case['name']}",
                        "status": "æˆåŠŸ",
                        "score": result['score'],
                        "max_score": case['max_score']
                    })
                    
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
                self.test_results.append({
                    "test": f"æ™ºèƒ½è¯„åˆ† - {case['name']}",
                    "status": "å¤±è´¥",
                    "error": str(e)
                })
    
    async def test_wrong_question_analysis(self):
        """æµ‹è¯•é”™é¢˜åˆ†æè®²è§£åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•é”™é¢˜åˆ†æè®²è§£åŠŸèƒ½...")
        
        test_cases = [
            {
                "name": "æ•°å­¦æ¦‚å¿µé”™è¯¯",
                "question": "æ±‚è§£ä¸ç­‰å¼ï¼š2x + 3 > 7",
                "correct_answer": "x > 2",
                "user_answer": "x > 4",
                "subject": "æ•°å­¦"
            },
            {
                "name": "è¯­æ–‡ç†è§£é”™è¯¯",
                "question": "åˆ†æã€Šé™å¤œæ€ã€‹ä¸­'ä¸¾å¤´æœ›æ˜æœˆ'çš„æ„å¢ƒ",
                "correct_answer": "è¡¨è¾¾äº†è¯—äººæ€ä¹¡ä¹‹æƒ…ï¼Œé€šè¿‡ä»°æœ›æ˜æœˆå¯„æ‰˜å¯¹æ•…ä¹¡çš„æ€å¿µ",
                "user_answer": "æå†™äº†å¤œæ™šçœ‹æœˆäº®çš„åœºæ™¯",
                "subject": "è¯­æ–‡"
            },
            {
                "name": "è‹±è¯­è¯­æ³•é”™è¯¯",
                "question": "é€‰æ‹©æ­£ç¡®çš„æ—¶æ€ï¼šHe _____ (go) to school every day.",
                "correct_answer": "goes",
                "user_answer": "go",
                "subject": "è‹±è¯­"
            },
            {
                "name": "ç‰©ç†è®¡ç®—é”™è¯¯",
                "question": "è®¡ç®—ç‰©ä½“ä»10ç±³é«˜åº¦è‡ªç”±è½ä½“çš„æ—¶é—´ï¼ˆg = 9.8 m/sÂ²ï¼‰",
                "correct_answer": "çº¦1.43ç§’",
                "user_answer": "1ç§’",
                "subject": "ç‰©ç†"
            },
            {
                "name": "åŒ–å­¦æ¦‚å¿µæ··æ·†",
                "question": "ä»€ä¹ˆæ˜¯åŒ–å­¦é”®ï¼Ÿ",
                "correct_answer": "åŒ–å­¦é”®æ˜¯åŸå­é—´é€šè¿‡ç”µå­è½¬ç§»æˆ–å…±äº«è€Œå½¢æˆçš„ç›¸äº’ä½œç”¨åŠ›",
                "user_answer": "åŒ–å­¦é”®æ˜¯åˆ†å­é—´çš„å¸å¼•åŠ›",
                "subject": "åŒ–å­¦"
            }
        ]
        
        for i, case in enumerate(test_cases, 1):
            print(f"\nğŸ“ æµ‹è¯•æ¡ˆä¾‹ {i}: {case['name']}")
            
            try:
                result = await self.ai_service.analyze_wrong_question(
                    case["question"],
                    case["user_answer"],
                    case["correct_answer"],
                    case["subject"]
                )
                
                # éªŒè¯ç»“æœæ ¼å¼
                required_fields = [
                    "error_analysis", "correct_solution", "knowledge_points",
                    "learning_guidance", "similar_questions", "personalized_encouragement",
                    "difficulty_assessment", "improvement_plan"
                ]
                
                missing_fields = [field for field in required_fields if field not in result]
                if missing_fields:
                    print(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                    self.test_results.append({
                        "test": f"é”™é¢˜åˆ†æ - {case['name']}",
                        "status": "å¤±è´¥",
                        "error": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}"
                    })
                else:
                    print(f"âœ… åˆ†æç»“æœ:")
                    print(f"   é”™è¯¯ç±»å‹: {result['error_analysis']['error_type']}")
                    print(f"   é”™è¯¯ä¸¥é‡ç¨‹åº¦: {result['error_analysis']['error_severity']}")
                    print(f"   æ ¹æœ¬åŸå› : {result['error_analysis']['root_cause']}")
                    print(f"   è§£é¢˜æ­¥éª¤æ•°: {len(result['correct_solution']['step_by_step'])}")
                    print(f"   å…³é”®æ¦‚å¿µæ•°: {len(result['correct_solution']['key_concepts'])}")
                    print(f"   å­¦ä¹ å»ºè®®æ•°: {len(result['learning_guidance']['focus_areas'])}")
                    print(f"   é¼“åŠ±è¯è¯­: {result['personalized_encouragement']['motivation_message']}")
                    
                    # æ˜¾ç¤ºè¯¦ç»†åˆ†æ
                    error_analysis = result['error_analysis']
                    print(f"   å¸¸è§é”™è¯¯: {', '.join(error_analysis['common_mistakes'])}")
                    print(f"   é”™è¯¯è®¤çŸ¥: {', '.join(error_analysis['misconceptions'])}")
                    
                    learning_guidance = result['learning_guidance']
                    print(f"   é‡ç‚¹å­¦ä¹ : {', '.join(learning_guidance['focus_areas'])}")
                    print(f"   ç»ƒä¹ å»ºè®®: {', '.join(learning_guidance['practice_suggestions'])}")
                    
                    self.test_results.append({
                        "test": f"é”™é¢˜åˆ†æ - {case['name']}",
                        "status": "æˆåŠŸ",
                        "error_type": result['error_analysis']['error_type'],
                        "severity": result['error_analysis']['error_severity']
                    })
                    
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
                self.test_results.append({
                    "test": f"é”™é¢˜åˆ†æ - {case['name']}",
                    "status": "å¤±è´¥",
                    "error": str(e)
                })
    
    async def test_enhanced_features(self):
        """æµ‹è¯•å¢å¼ºåŠŸèƒ½ç‰¹æ€§"""
        print("\nğŸ” æµ‹è¯•å¢å¼ºåŠŸèƒ½ç‰¹æ€§...")
        
        # æµ‹è¯•ä¸åŒé¢˜ç›®ç±»å‹çš„è¯„åˆ†å·®å¼‚
        print("\nğŸ“Š æµ‹è¯•ä¸åŒé¢˜ç›®ç±»å‹çš„è¯„åˆ†å·®å¼‚...")
        
        question_content = "è®¡ç®— 15 Ã— 8 çš„ç»“æœ"
        standard_answer = "120"
        student_answer = "120"
        max_score = 5
        
        question_types = ["single_choice", "fill_blank", "short_answer", "essay"]
        
        for q_type in question_types:
            try:
                result = await self.ai_service.smart_grading(
                    question_content, standard_answer, student_answer, q_type, max_score
                )
                
                print(f"   é¢˜ç›®ç±»å‹: {q_type}")
                print(f"   æ€»åˆ†: {result['score']}/{max_score}")
                print(f"   å†…å®¹å‡†ç¡®æ€§: {result['accuracy_score']}")
                print(f"   é€»è¾‘å®Œæ•´æ€§: {result['logic_score']}")
                print(f"   è¡¨è¾¾è§„èŒƒæ€§: {result['expression_score']}")
                print(f"   åˆ›æ–°æ€ç»´: {result['creativity_score']}")
                print()
                
            except Exception as e:
                print(f"âŒ {q_type} ç±»å‹æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•é”™è¯¯ç±»å‹è¯†åˆ«
        print("\nğŸ“Š æµ‹è¯•é”™è¯¯ç±»å‹è¯†åˆ«...")
        
        test_answers = [
            ("", "ä¸¥é‡é”™è¯¯ - æœªä½œç­”"),
            ("12", "éƒ¨åˆ†é”™è¯¯ - ç­”æ¡ˆä¸å®Œæ•´"),
            ("120", "å®Œå…¨æ­£ç¡®"),
            ("121", "è½»å¾®é”™è¯¯ - è®¡ç®—é”™è¯¯"),
            ("100", "ä¸­ç­‰é”™è¯¯ - æ¦‚å¿µé”™è¯¯")
        ]
        
        for answer, description in test_answers:
            try:
                result = await self.ai_service.analyze_wrong_question(
                    "è®¡ç®— 15 Ã— 8 çš„ç»“æœ",
                    answer,
                    "120",
                    "æ•°å­¦"
                )
                
                print(f"   å­¦ç”Ÿç­”æ¡ˆ: '{answer}' ({description})")
                print(f"   è¯†åˆ«é”™è¯¯ç±»å‹: {result['error_analysis']['error_type']}")
                print(f"   é”™è¯¯ä¸¥é‡ç¨‹åº¦: {result['error_analysis']['error_severity']}")
                print()
                
            except Exception as e:
                print(f"âŒ é”™è¯¯ç±»å‹è¯†åˆ«æµ‹è¯•å¤±è´¥: {e}")
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ æ™ºèƒ½è¯„åˆ†ä¸é”™é¢˜è®²è§£åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r["status"] == "æˆåŠŸ"])
        failed_tests = total_tests - successful_tests
        
        print(f"\nğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"   æˆåŠŸæ•°: {successful_tests}")
        print(f"   å¤±è´¥æ•°: {failed_tests}")
        print(f"   æˆåŠŸç‡: {(successful_tests/total_tests*100):.1f}%")
        
        print(f"\nâœ… æˆåŠŸæµ‹è¯•:")
        for result in self.test_results:
            if result["status"] == "æˆåŠŸ":
                if "score" in result:
                    print(f"   {result['test']} - å¾—åˆ†: {result['score']}/{result['max_score']}")
                elif "error_type" in result:
                    print(f"   {result['test']} - é”™è¯¯ç±»å‹: {result['error_type']} ({result['severity']})")
                else:
                    print(f"   {result['test']}")
        
        if failed_tests > 0:
            print(f"\nâŒ å¤±è´¥æµ‹è¯•:")
            for result in self.test_results:
                if result["status"] == "å¤±è´¥":
                    print(f"   {result['test']} - é”™è¯¯: {result['error']}")
        
        print(f"\nğŸ¯ åŠŸèƒ½ä¼˜åŒ–æ€»ç»“:")
        print("   1. âœ… æ™ºèƒ½è¯„åˆ†ç®—æ³•å·²ä¼˜åŒ–ï¼Œæ”¯æŒå¤šç»´åº¦è¯„åˆ†")
        print("   2. âœ… é”™é¢˜åˆ†æè®²è§£å·²å¢å¼ºï¼Œæä¾›ä¸ªæ€§åŒ–å»ºè®®")
        print("   3. âœ… æ”¯æŒä¸åŒé¢˜ç›®ç±»å‹çš„å·®å¼‚åŒ–è¯„åˆ†")
        print("   4. âœ… é”™è¯¯ç±»å‹è¯†åˆ«æ›´åŠ ç²¾å‡†")
        print("   5. âœ… æä¾›è¯¦ç»†çš„å­¦ä¹ æŒ‡å¯¼å’Œé¼“åŠ±")
        print("   6. âœ… å¢å¼ºçš„é™çº§æ–¹æ¡ˆï¼Œç¡®ä¿åŠŸèƒ½ç¨³å®šæ€§")
        
        print(f"\nğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ™ºèƒ½è¯„åˆ†ä¸é”™é¢˜è®²è§£åŠŸèƒ½...")
    
    tester = SimpleAIFeaturesTest()
    
    # æµ‹è¯•æ™ºèƒ½è¯„åˆ†åŠŸèƒ½
    await tester.test_smart_grading()
    
    # æµ‹è¯•é”™é¢˜åˆ†æè®²è§£åŠŸèƒ½
    await tester.test_wrong_question_analysis()
    
    # æµ‹è¯•å¢å¼ºåŠŸèƒ½ç‰¹æ€§
    await tester.test_enhanced_features()
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    tester.generate_test_report()

if __name__ == "__main__":
    asyncio.run(main()) 